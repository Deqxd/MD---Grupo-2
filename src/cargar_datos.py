import pandas as pd
import os
import csv
import chardet
from unidecode import unidecode

# ‚úÖ CONSERVAR: Este import es √∫til para limpiar tildes y caracteres especiales
# ‚úÖ chardet y csv.Sniffer ayudan a detectar codificaci√≥n y delimitador autom√°ticamente


# ---------- Funci√≥n auxiliar para detectar y leer CSV correctamente ----------
def cargar_csv_robusto(ruta_archivo):
    """Lee un CSV detectando autom√°ticamente encoding y delimitador."""

    # ‚úÖ CONSERVAR: detecci√≥n autom√°tica de encoding
    with open(ruta_archivo, 'rb') as f:
        enc = chardet.detect(f.read(20000))['encoding']

    # ‚úÖ CONSERVAR: detecci√≥n autom√°tica de delimitador
    with open(ruta_archivo, 'r', encoding=enc, errors='ignore') as f:
        sample = f.read(2000)
        f.seek(0)
        try:
            dialect = csv.Sniffer().sniff(sample)
            delim = dialect.delimiter
        except:
            delim = ';'  # üî∏ RECOMENDACI√ìN: podr√≠as probar primero con ',' antes que ';'
            # Ejemplo: delim = ',' if ',' in sample else ';'

    # ‚úÖ CONSERVAR: lectura segura del archivo CSV
    df = pd.read_csv(
        ruta_archivo,
        encoding=enc,
        delimiter=delim,
        quotechar='"',
        skip_blank_lines=True,
        on_bad_lines='skip',
        engine='python'
    )

    # üî∏ MEJORAR: usa `df.columns.str.contains` para evitar errores con tipos
    if df.shape[0] > 0 and df.columns.astype(str).str.contains("CODIGO", case=False).any():
        # ‚ö†Ô∏è Tu condici√≥n actual revisa la primera fila, no las columnas.
        # Se reemplaza por una validaci√≥n correcta:
        pass  # no eliminar filas aqu√≠, esto se manejar√° despu√©s si es necesario

    return df


# ---------- Funci√≥n principal ----------
def cargar_datos():
    # ‚úÖ Ruta ra√≠z del proyecto
    ruta_actual = os.path.dirname(os.path.abspath(__file__))
    ruta_raiz = os.path.dirname(ruta_actual)
    ruta_base = os.path.join(ruta_raiz, "datos_admision")

    if not os.path.exists(ruta_base):
        raise FileNotFoundError(f"No se encontr√≥ la carpeta de datos: {ruta_base}")

    df_total = pd.DataFrame()

    # ‚úÖ Funci√≥n para limpiar nombres de columnas
    def limpiar_nombre(col):
        col = unidecode(str(col).strip().upper())
        # üî∏ RECOMENDACI√ìN: agrega una limpieza m√°s gen√©rica
        col = (col.replace("&OACUTE", "O")
                  .replace("(PRIMERA OPCION)", "")
                  .replace("  ", " ")
                  .strip())
        return col

    # ‚úÖ Recorrer carpetas y archivos CSV
    for carpeta in os.listdir(ruta_base):
        ruta_carpeta = os.path.join(ruta_base, carpeta)
        if os.path.isdir(ruta_carpeta):
            for archivo in os.listdir(ruta_carpeta):
                if archivo.lower().endswith(".csv"):
                    ruta_archivo = os.path.join(ruta_carpeta, archivo)
                    print(f"üìÇ Cargando {ruta_archivo}...")

                    # ‚úÖ Leer archivo de forma robusta
                    df = cargar_csv_robusto(ruta_archivo)

                    # ‚úÖ Limpieza de nombres de columnas
                    df.columns = [limpiar_nombre(c) for c in df.columns]

                    # ‚úÖ Mapeo flexible de columnas esperadas
                    columnas_validas = {
                        "CODIGO": [c for c in df.columns if "COD" in c],
                        "APELLIDOS Y NOMBRES": [c for c in df.columns if "APELL" in c],
                        "ESCUELA PROFESIONAL": [c for c in df.columns if "ESCUELA" in c],
                        "PUNTAJE": [c for c in df.columns if "PUNTAJE" in c or "PUNTAJ" in c],
                        "MERITOE.P": [c for c in df.columns if "MERITO" in c],
                        "OBSERVACION": [c for c in df.columns if "OBSERV" in c],
                    }

                    # ‚úÖ Crear DataFrame temporal estandarizado
                    df_temp = pd.DataFrame()
                    for col_final, posibles in columnas_validas.items():
                        if posibles:
                            df_temp[col_final] = df[posibles[0]]
                        else:
                            df_temp[col_final] = None  # Mantener consistencia de columnas

                    # ‚úÖ Agregar columna del proceso (ej: 2023-II)
                    df_temp["PROCESO"] = carpeta

                    # ‚úÖ Concatenar al dataset total
                    df_total = pd.concat([df_total, df_temp], ignore_index=True)

    # ‚úÖ Mensaje final
    print(f"\n‚úÖ Datos cargados y estandarizados: {df_total.shape[0]} registros totales.\n")
    print(f"Columnas finales: {list(df_total.columns)}")

    # ‚úÖ Guardar archivo consolidado
    carpeta_resultados = os.path.join(ruta_raiz, "resultados")
    os.makedirs(carpeta_resultados, exist_ok=True)
    ruta_salida = os.path.join(carpeta_resultados, "datos_unificados.csv")

    df_total.to_csv(ruta_salida, index=False, encoding="utf-8-sig")
    print(f"üíæ Archivo unificado guardado en: {ruta_salida}")

    return df_total


# ---------- Ejecuci√≥n directa ----------
if __name__ == "__main__":
    df = cargar_datos()
    print("\nVista previa:")
    print(df.head())

